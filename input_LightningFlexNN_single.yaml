####################################################################################################
# Arguments for training of single flexMLP network
####################################################################################################
# basic contruction of Loader, LightningFlexMLP and pl.Trainer cannot be changed

# Generate class including train, val and test data
DataLoader:
  type: TabularLoader
#  load_DataLoader:
#    path: TabularLoader_example.pkl
  create_DataLoader:
    raw_data_path: example_samples.csv                            # .h5, .csv, .txt
    features: [T_0, PV]
    labels: [T, wH2O, yCO2]
    validation_data:
#      load_data:
#        path: None                                  # add_file_path_path
      split_data:
        method: explicit                            # options=[random, explicit, percentage]
        params:
          T_0: [940]                                        # adjust feature name
    test_data:
#      load_data:
#        path: None
      split_data:
        method: explicit
        params:                                    # only select if method == sample
          T_0: [945]                                       # change name of feature
#    save_Loader:
#      path: TabularLoader_example.pkl

# hparams for model
Model:
  type: LightningFlexNN
#  load_model:
#    path: lightning_logs/version_19/checkpoints/epoch=14.ckpt
  create_model:
    height: 39
    width: 31
    depth: 1
    layers:
      - type: Conv2d
        params:
          channels: 20
          kernel_size: 4
          # stride: 1 # optional
          # padding: 1 # optional
      - type: MaxPool2d
        params:
          kernel_size: 2
          # stride: int
          # padding: int
      - type: Conv2d
        params:
          channels: 40
          kernel_size: 3
      - type: MaxPool2d
        params:
          kernel_size: 2
      - type: Conv2d
        params:
          channels: 60
          kernel_size: 3
      - type: MaxPool2d
        params:
          kernel_size: 2
#      - type: BatchNorm2d
#        params:
#          num_features: 100
    MLP_layer:
      n_out: 10
      hidden_layer: [64, 128, 64]
    output_relu: LogSoftmax  # optional
    activation: ReLU  # optional
  params:  # all have defaults
    loss: RelativeMSELoss
    optimizer:
      type: Adam
      params:
        lr: 1.e-3
    scheduler:
      execute: True
      type: ReduceLROnPlateau
      params:
        cooldown: 2
        patience: 3
        min_lr: 1.e-8                                   # Notation including point is necessary otherwise will be read as str
    num_workers: 5
    batch: 64

# training parameters of flexMLP
Trainer:
  params:
    max_epochs: 10
    profiler: True
    # resume_from_checkpoint: False                       # can only be true if model loaded from checkpoint
  callbacks:
    - type: EarlyStopping
      params:
        monitor: val_loss
        patience: 12
        mode: min
#    - type: LearningRateLogger  # only working if lr scheduler active and if a logger is selected
    - type: Checkpointing
      params:
        filepath: checkpoints/try
        save_top_k: 1  # other params in documentation
        period: 0
#  logger:
#    - type: comet-ml
#      params:
#        api_key: ENlkidpOntcgkoGGs5nkyhFv5
#        project_name: general
#        workspace: proth
#        experiment_name: try_out
#    - type: tensorboard

