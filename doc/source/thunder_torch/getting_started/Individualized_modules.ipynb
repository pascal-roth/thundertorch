{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Individual Modules\n",
    "==================\n",
    "\n",
    "Machine Learning is a very broad field and can be used in multiple occasions. Consequently, the provided elements of the Toolbox may be insufficient for the addressed tasks and an indivdual implementation of a model, a dataLoader, a callback or certain functions might be necessary. The toolbox allows this extension without the need to change the source code in any way. In the following, the different modules are introduced where individual extensions are possible, followed by a tutorial on how to add individual modules.\n",
    "\n",
    "\n",
    "Expandable modules\n",
    "------------------\n",
    "- models\n",
    "    - pre-implemented source: 'thunder.models'\n",
    "    - for new models please keep attention to the model template (thunder.models._LightningModelTemplate.LightningModelTemplate) and include the functions mentioned there since they will be used when in training\n",
    "- DataLoader\n",
    "    - pre-implemented source: 'thunder.loader'\n",
    "    - for new models please keep attention to the DataLoader template (thunder.loader._DataLoaderTemplate.DataLoaderTemplate) and include the functions mentioned there\n",
    "- callbacks\n",
    "    - pre-implemented source: 'pytorch_lightning.callbacks', 'thunder.callbacks'\n",
    "    - tutorial on how to construct a callback can be found [here](./Callbacks.html)\n",
    "- activation function\n",
    "    - pre-implemented source: ['torch.nn'](https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity)\n",
    "- loss function\n",
    "    - pre-implemented source: ['torch.nn'](https://pytorch.org/docs/stable/nn.html#loss-functions), 'thunder.models'\n",
    "- optimizer\n",
    "    - pre-implemented source: ['torch.optim'](https://pytorch.org/docs/stable/optim.html)\n",
    "- learning rate scheduler\n",
    "    - pre-implemented source: ['torch.optim.lr_scheduler'](https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate)\n",
    "\n",
    "\n",
    "How to add an individual module?\n",
    "--------------------------------\n",
    "Let's say we want to add a new loss function which computes the relative MSELoss (function implemented in \"thunder.models._ losses.RelativeMSELoss\"). We have initialized the project using ml_init in our current working directory. In order to add an individual loss function, we have to pack it in a module (directory with \"__ init __ .py\". Therefore, the following example structure will be implemented:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ".\n",
    "+-- TabularLoader_LightningFlexMLP.yaml\n",
    "+-- MultiModelTraining.yaml\n",
    "+-- individual_module\n",
    "|   +-- __init__.py\n",
    "|   +-- myloss.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the __ init __ .py as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from .myloss import RelativeMSE\n",
    "\n",
    "__all__ == ['RelativeMSE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And myloss.py with the defintion of the class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelativeMSE(nn.Module):\n",
    "    def __init__(self, ...):\n",
    "        ...\n",
    "    \n",
    "    def forward(self, y, t):\n",
    "        ...\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If now the path to our indvidual module should be added to the list of sources for the loss function, thunder.utils.training.train_config is used. This function automatically adds the given module(s) to all expandable modules. If the YAML template is used, the module path has to be added to the key \"source_files\" in the config tree. An example for both input strategies is given here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thunder.utils import train_config\n",
    "\n",
    "argsConfig = {'source_files': 'individual_module'}\n",
    "train_config(argsConfig)\n",
    "\n",
    "# then initialize model with the loss_fn='RelativeMSE' and start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config:\n",
    "  source_files: individual_module\n",
    "  \n",
    "...\n",
    "\n",
    "Model:\n",
    "  ...\n",
    "  params:\n",
    "    loss: RelativeMSE\n",
    "    ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
