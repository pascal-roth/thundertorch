{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trainer\n",
    "=======\n",
    "\n",
    "After having organized the model as LightningModule, the Trainer automates everything else. It governs training and testing, can decide whether and when a model is saved, if the losses are logged, how many epochs to train and so on ... In case only default values are used and the DataLoader includes training, validation, and test data set, the trainer is reduced to the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "\n",
    "trainer = pl.Trainer()\n",
    "trainer.fit(model, train_dataloader=dataLoader.train_dataloader(), val_dataloaders=dataLoader.val_dataloader())\n",
    "trainer.test(model, test_dataloaders=dataLoader.test_dataloader())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters\n",
    "----------\n",
    "\n",
    "All parameters of the trainer class are defined in the [PyTorch Lightning Docs](https://pytorch-lightning.readthedocs.io/en/0.7.6/trainer.html#trainer-flags). Here the most commonly used are presented:\n",
    "\n",
    "- max_epochs: Stop training once this number of epochs is reached\n",
    "- gpus: Number of GPUs to train on or which GPUs to train on\n",
    "- profiler: profile individual steps during training and assist in identifying bottlenecks\n",
    "- resume_from_checkpoint: resume training from a specific checkpoint pass in the path here\n",
    "- fast_dev_run: Runs 1 batch of train, test, and val to find any bugs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Callbacks\n",
    "---------\n",
    "\n",
    "PyTorch Lightning has a callback system to execute arbitrary code. Callbacks should capture NON-ESSENTIAL logic that is NOT required for your LightningModule to run. A detailed overview of all Callbacks can be found in the [PyTorch Lightning Docs](https://pytorch-lightning.readthedocs.io/en/0.7.6/callbacks.html). The most important callbacks are:\n",
    "\n",
    "- EarlyStopping:\n",
    "    - Stop training when a monitored quantity has stopped improving.\n",
    "    - has its own keyword in trainer class\n",
    "- LearningRateLogger\n",
    "    - Log learning rate for lr schedulers during training\n",
    "    - logger cannot be false and lr scheduler has to be activated\n",
    "- Checkpointing\n",
    "    - Automatically save model checkpoints during training\n",
    "    - !!! Callback name changed from the Lightning Implementation in order to allow a checkpoint label without epoch. As a consequence, further training can be initialized in the same script without entering the name with the corresponding epoch!!!\n",
    "    - has an own keyword in the trainer class\n",
    "\n",
    "A more detailed explanation is given [here](./Callbacks.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logger\n",
    "------\n",
    "\n",
    "It is recommended to use the [Comet Logger](https://www.comet.ml/site/). In order to use this logger, a profile has to be made and the code has to be equipped with:\n",
    "\n",
    "- api_key: personal api\n",
    "- project_name: str\n",
    "- workspace: str\n",
    "- experiment_name: str\n",
    "\n",
    "However, the usage of other logger systems is possible. An overview is given in the [PyTorch Lightning Docs](https://pytorch-lightning.readthedocs.io/en/0.7.6/loggers.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
