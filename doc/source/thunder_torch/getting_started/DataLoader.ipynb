{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataLoader \n",
    "==========\n",
    "\n",
    "DataLoaders are a central element when working with NN. They provide an iterable over the given dataset. This toolbox has pre-implemented DataLoaders for different kinds of datasets. However, own DataLoaders can be created by following the basic structure of the DataLoaderTemplate.py. Since the DataLoader is passed directly to the Lightning Trainer class when the model is trained/ tested, the necessary preprocessing steps have to be included in the DataLoader. Furthermore, the DataLoader has to consist of data for training, validation, and testing. If those three datasets are not defined prior to the training, a default split is performed. \n",
    "\n",
    "Initialization Methods\n",
    "----------------------\n",
    "A DataLoader can be initialized by a direct code implementation or by using the yaml structure. Thereby, each DataLoader has a yaml template saved as a staticmethod. In order to employ the yaml file, the utils functions can be used. The check_argsLoader(args_yaml) function is not mandatory, however, the usage is recommended in order to detect possible errors and secure that the intended output is provided. In the following, the different approaches are demonstrated using the TabularLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# direct code implementation\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from thunder import loader\n",
    "\n",
    "example_df = pd.DataFrame(np.random.rand(10000, 5))\n",
    "example_df.columns = ['feature_1', 'feature_2', 'feature_3', 'label_1', 'label_2']\n",
    "\n",
    "features = ['feature_1', 'feature_2', 'feature_3']\n",
    "labels = ['label_1', 'label_2']\n",
    "\n",
    "dataLoader = loader.TabularLoader(example_df, features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the yaml_template\n",
    "\n",
    "import yaml\n",
    "from thunder.utils import *\n",
    "\n",
    "args_yaml = parse_yaml('path.yaml')\n",
    "check_argsLoader(args_yaml['dataloader'])\n",
    "dataLoader = get_dataLoader(args_yaml['dataloader'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataLoader Classmethods\n",
    "-----------------------\n",
    "Next to the direct initialization as seen above, DataLoader can be created directly from different files or by using the information saved in a model checkpoint. For both cases certain constraints have to be known:\n",
    "\n",
    "- Read from a file\n",
    "    - supported file datatypes: .csv, .txt, .h5, .ulf\n",
    "    - there has to be only one key stored in the HDFStore \n",
    "- Read from checkpoint\n",
    "    - !!! The parameters of the Loader have to be included in the hparams of the model. Therefore, the model function \"update_hparams\" has to be executed as follows: \"model.hparams_update(update_dict={'lparams': dataLoader.lparams})\" !!!\n",
    "    - the data path to training, validation and test dataset (in case the validation and/ or test set are individual loaded datasets and not split from the training set) has to be the same as the one when the DataLoader has been created in the first place\n",
    "\n",
    "In the following the two approaches are shown using the TabularLoader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read from file\n",
    "\n",
    "from thunder import loader\n",
    "\n",
    "features = ['feature_1', 'feature_2', '...']\n",
    "labels = ['label_1', 'label_2', '...']\n",
    "\n",
    "dataLoader = loader.TabularLoader.read_from_file('file_path.csv', features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read from checkpoint\n",
    "\n",
    "from thunder import loader\n",
    "\n",
    "dataLoader = loader.TabularLoader.read_from_checkpoint('file_path.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save and Load DataLoader\n",
    "------------------------\n",
    "\n",
    "Besides, it is possible to save and load DataLoader. Therefore, the pickle data format is chosen. The corresponding functions are called \"save\" and \"load\" with the file_path.pkl as only input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataLoader\n",
    "dataLoader.save('file_path.pkl')\n",
    "\n",
    "# load dataLoader\n",
    "dataLoader = loader.TabularLoader.load('file_path.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation and Test Dataset \n",
    "---------------------------\n",
    "\n",
    "Prior to the use of the DataLoader an input of the pl.Trainer class, the DataLoader has to include training, validation, and test data set. These datasets can be obtained in two different ways. One way is to load individual datasets for validation and/ or testing. Thereby, the loading can be performed when the Loader is initialized or afterward by calling the functions \"add_val_data\" / \"add_test_data\". The same datatypes as for the training data are supported (.csv, .txt, .h5). An example using the TabularLoader is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thunder import Loader\n",
    "\n",
    "# load validation and test data within initialization\n",
    "dataLoader = loader.TabularLoader.read_from_file('file_path.csv', features, labels, val_path='path_to_val_data.csv', \n",
    "                                                 test_path='path_to_test_data.csv')\n",
    "\n",
    "# load data after initialization\n",
    "dataLoader = loader.TabularLoader.read_from_file('file_path.csv', features, labels)\n",
    "dataLoader.add_val_data('path_to_val_data.csv')\n",
    "dataLoader.add_test_data('path_to_test_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case validation and test data are not individual datasets, they have to be separated from the training set. The toolbox provides three different approaches to fulfill the separation. These are:\n",
    "\n",
    "- a random approach ('method': 'random', 'params': float): \n",
    "    - a certain percentage of samples is taken randomly \n",
    "- a percentage approach ('method': 'percentage', 'params': {''feature_1': float, 'feature_2': float, ...}):\n",
    "    - Split the data by extracting the different values of a feature and randomly pick a certain percentage of it. All samples where the feature is equal to one of those values are extracted into x_split / y_split. However, if the feature has a different value for each sample, the method is equal to random. Furthermore, the size of x_split / y_split can differ from the percentage of values taken. In split_params the percentage can be defined for an arbitrary number of features.\n",
    "- an explicit appraoch ('method': 'explicit', 'params': {''feature_1': [value_1, value_2], 'feature_2': [value_1, value_2], ...}): \n",
    "    - Split data according to explicit values of the different features. It is possible to define an arbitrary number of values for the different features.\n",
    "    \n",
    "Splitting the training data can be performed either by initializing the DataLoader object or by calling the functions \"val_split\"/ \"test_split\". In the following an example including all functions using the TabularLoader is shown:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thunder import Loader\n",
    "\n",
    "# load validation and test data within initialization\n",
    "dataLoader = loader.TabularLoader.read_from_file('file_path.csv', features, labels, val_split={'method': 'random', 'params': 0.2}, \n",
    "                                                 test_split={'method': 'percentage', 'params': {'feature_1': 0.2}})\n",
    "\n",
    "# load data after initialization\n",
    "dataLoader = loader.TabularLoader.read_from_file('file_path.csv', features, labels)\n",
    "dataLoader.val_split(method='random', params=0.2})\n",
    "dataLoader.test_split(method='explicit', params={'feature_1': ['value_1', 'value_2']})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
