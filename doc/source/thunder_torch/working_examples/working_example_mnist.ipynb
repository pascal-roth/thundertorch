{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working Example: Mnist\n",
    "=====================\n",
    "\n",
    "In order to demonstrate how the Toolbox can be employed for Two-Dimensional (e.g. Images) input data in a classification task, this example uses the Mnist Dataset. An introduction to the Dataset itself and its origin can be found [here](http://yann.lecun.com/exdb/mnist/). The set includes 60000 training and 10000 test images with a size of 28x28 pixels. In total 10 different classes can be identified. As mentioned, there are different ways to implement the model. Here both strategies (yaml and code interface) are demonstrated. \n",
    "\n",
    "The example is structured as follows:\n",
    "1. Load the Mnist dataset\n",
    "2. Generate Model with yaml file\n",
    "3. Generate Model by code implementation\n",
    "4. Train model\n",
    "\n",
    "\n",
    "Load Mnist Dataset\n",
    "-------------------\n",
    "The Mnist Data set is included in the torchvision datasets. In general, it is possible to load the set and pass it nearly into the torch.utils.data.DataLoader method. However, with the toolbox, this is a little bit tricky since the model's dtype is set to double. This default change is necessary in order to export the model to C++. As a consequence, the model expects a double input so that the dataset tensor has to be changed manually to double, and then the channels have to be added by reshaping the images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "mnist_train = datasets.MNIST('./data', train=True, download=True, transform=transform) \n",
    "x_train = mnist_train.data.double()\n",
    "x_train = x_train.reshape((60000, 1, 28, 28))\n",
    "y_train = mnist_train.targets.double()\n",
    "train = torch.utils.data.TensorDataset(x_train, y_train)\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=64, shuffle=False, num_workers=10)\n",
    "\n",
    "mnist_val = datasets.MNIST('./data', train=False, download=True, transform=transform)\n",
    "x_val = mnist_val.data.double()\n",
    "x_val = x_val.reshape((10000, 1, 28, 28))\n",
    "y_val = mnist_val.targets.double()\n",
    "val = torch.utils.data.TensorDataset(x_val, y_val)\n",
    "val_loader = torch.utils.data.DataLoader(val, batch_size=64, shuffle=False, num_workers=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a model with yaml interface\n",
    "----------------------------------\n",
    "\n",
    "Using the yaml interface is considered to be more structured and less likely to fail. In the case of this example, only the model is creating using a yaml file, the trainer as well as the data are directly implemented. In order to construct the yaml, you don't have to start from scratch since each model has a pre-implemented yaml template. To obtain the yaml file, we just call the staticmethod yml_template, pass it an empty list and then copy the output into a yaml file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thunder.models import LightningFlexNN\n",
    "\n",
    "print(LightningFlexNN.yaml_template([]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model:\n",
    "  type: LightningFlexNN\n",
    "  '###INFO###': load_model and create_model are mutually exclusive\n",
    "  load_model:\n",
    "    path: name.ckpt\n",
    "  create_model:\n",
    "    width: int\n",
    "    height: int\n",
    "    depth: int\n",
    "    layers:\n",
    "    - type: torch.nn module\n",
    "      params:\n",
    "        module_param_1: value\n",
    "        module_param_2: value\n",
    "    - type: e. g. Conv2d\n",
    "      params:\n",
    "        kernel_size: 3\n",
    "        channels: 20\n",
    "    - type: e. g. MaxPool2d\n",
    "      params:\n",
    "        kernel_size: 2\n",
    "    MLP_layer:\n",
    "      n_out: int\n",
    "      hidden_layer:\n",
    "      - int\n",
    "      - int\n",
    "      - '...'\n",
    "    output_activation: 'str (default: None)'\n",
    "    activation: 'str (default: ReLU)'\n",
    "  params:\n",
    "    loss: str (default:MSELoss)\n",
    "    optimizer:\n",
    "      type: 'str (default: Adam)'\n",
    "      params:\n",
    "        lr: 'float (default: 1.e-3'\n",
    "    scheduler:\n",
    "      execute: ' bool (default: False)'\n",
    "      type: name\n",
    "      params:\n",
    "        cooldown: int\n",
    "        patience: int\n",
    "        min_lr: float\n",
    "    num_workers: 'int (default: 10)'\n",
    "    batch: 'int (default: 64)'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This output is then modified according to the task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model:\n",
    "  type: LightningFlexNN\n",
    "  create_model:\n",
    "    width: 28\n",
    "    height: 28\n",
    "    depth: 1\n",
    "    layers:\n",
    "    - type: Conv2d\n",
    "      params:\n",
    "        kernel_size: 3\n",
    "        channels: 16\n",
    "    - type: MaxPool2d\n",
    "      params:\n",
    "        kernel_size: 2\n",
    "    MLP_layer:\n",
    "      n_out: 10\n",
    "      hidden_layer:\n",
    "      - 64\n",
    "    output_activation: LogSigmoid\n",
    "  params:\n",
    "    loss: CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After adjusting the yaml file for the used case, the model is created using the utils function \"get_model\". It is further recommended to use check_argsmodel in order to detect possible mistakes made while changing the yaml file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thunder.utils import get_model, check_argsModel\n",
    "import yaml\n",
    "\n",
    "argsYaml = yaml.load('path.yaml', Loader=yaml.FullLoader)\n",
    "check_argsModel(argsYaml['Model'])\n",
    "model = get_model(argsYaml['Model'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Model by direct implementation\n",
    "---------------------------------------\n",
    "\n",
    "Different ways to construct the Namespace object needed to construct a model are given in [Model Documentation](../getting_started/Models.html). Here the Namespace is converted out of a dict. In order to quickly generated the dict, it can be copied out of the yml template function of the used model and then adjusted. It is possible to pass the dict again to the get_model function. Here, however, you can see the steps that are performed. Thereby, the model is first created and updated by the hyperparameters defined in \"params\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thunder.models import LightningFlexNN\n",
    "import argparse\n",
    "\n",
    "model_dict = {'create_model': {'width': 28, 'height': 28, 'depth': 1,\n",
    "                               'layers': [{'type': 'Conv2d', 'params': {'kernel_size': 3, 'channels': 16, 'stride': 1}},\n",
    "                                          {'type': 'MaxPool2d', 'params': {'kernel_size': 2}}],\n",
    "                               'MLP_layer': {'n_out': 10, 'hidden_layer': [64]}},\n",
    "              'params': {'loss': 'CrossEntropyLoss'}}\n",
    "\n",
    "model = LightningFlexNN(argparse.Namespace(**model_dict['create_model']))\n",
    "model.hparams_update(model_dict['params'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model\n",
    "-----------\n",
    "\n",
    "Training is performed using the Lighting Trainer class. Since in this example we only want to control that the model is working correctly, the fast_dev_run flag is set to True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "\n",
    "trainer = pl.Trainer(fast_dev_run=True, logger=False)\n",
    "trainer.fit(model, train_dataloader=train_loader, val_dataloaders=val_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
